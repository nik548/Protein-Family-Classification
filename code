from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import sklearn
import sklearn.datasets
import sklearn.tree
import sklearn.metrics
import sklearn.ensemble
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score
from collections import OrderedDict
import os
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from collections import OrderedDict
from mpl_toolkits.mplot3d import Axes3D
from sklearn.preprocessing import StandardScaler


data_partitions_dirpath = '/content/drive/My Drive/Research - Machine Learning/Deep Learning Models/random_split'


def read_all_shards(partition='dev', data_dir=data_partitions_dirpath):
    shards = []
    for fn in os.listdir(os.path.join(data_dir, partition)):
        with open(os.path.join(data_dir, partition, fn)) as f:
            shards.append(pd.read_csv(f, index_col=None))
    return pd.concat(shards)

test = read_all_shards('test')
val = read_all_shards('dev')
train = read_all_shards('train')

print(train, test, val)


test.isnull().sum()
test = test.dropna()
val.isnull().sum()
val = val.dropna()
train.isnull().sum()
train = train.dropna()

classes = train['family_accession'].value_counts()[:750].index.tolist()
len(classes)

train_sm = train.loc[train['family_accession'].isin(classes)].reset_index()
val_sm = val.loc[val['family_accession'].isin(classes)].reset_index()
test_sm = test.loc[test['family_accession'].isin(classes)].reset_index()

print(len(train_sm))
print(len(val_sm))
print(len(test_sm))
